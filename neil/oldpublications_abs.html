<HTML>
<HEAD>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta http-equiv="Content-Language" content="en-us">
<meta name="GENERATOR" content="Microsoft FrontPage 5.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Neil Lawrence's Abstracts</title>
<TITLE>Neil Lawrence's Abstracts</TITLE>
<LINK href=bibstyle.css rel=STYLESHEET type=text/css>
<meta name="Microsoft Border" content="tl, default">
</HEAD>
<BODY><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td>

<h1 align="center">
</h1>

<p align="center">
</p>
<p align="center">&nbsp;</p>

</td></tr><!--msnavigation--></table><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td valign="top" width="1%">

<p>


</p>

</td><td valign="top" width="24"></td><!--msnavigation--><td valign="top">
<!-- Start of BibTeX-generated HTML -->
<hr>
<H2>Journal Papers</H2>
<!-- citation: (Lerner:comparison01) -->
<A NAME=Lerner:comparison01>
<HR><P CLASS=CITATION-ABS>
Lerner, B. and N.&nbsp;D. Lawrence (2001).
<SPAN CLASS=BIB-TITLE>A comparison of state-of-the-art classification
  techniques with application to cytogenetics</SPAN>.
<SPAN CLASS=BIB-JOURNAL>Neural Computing and Applications</SPAN> &nbsp;<SPAN
  CLASS=BIB-VOLUME>10</SPAN>(1), 39&#150;47.
 [</a><a HREF=
comparison.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Several state-of-the-art techniques: a neural network, Bayesian neural network,
  support vector machine and naive Bayesian classifier are experimentally
  evaluated in discriminating fluorescence in-situ hybridization (FISH)
  signals. Highly accurate classification of signals from real data and
  artifacts of two cytogenetic probes (colours) is required for detecting
  abnormalities in the data. More than 3,100 FISH signals are classified by the
  techniques into colour and as real or artifact with accuracies of around 98%
  and 88%, respectively. The results of the comparison also show a trade-off
  between simplicity represented by the naive Bayesian classifier and high
  classification performance represented by the other techniques.</P>

<hr>
<H2>Refereed Conference Papers</H2>

<!-- citation: (Seeger:forward03) -->
<A NAME=Seeger:forward03>
<HR><P CLASS=CITATION-ABS><span lang="en-gb">Seeger, M., C. K. I. Williams and 
N. D. Lawrence (2003) </span>
<SPAN CLASS=BIB-TITLE>Fast <span lang="en-gb">Forward Selection to Speed Up 
Sparse Gaussian Process Regression. </span></SPAN>&nbsp;<span lang="en-gb">To 
appear at Workshop on AI and Statistics 9 (2003)</span>.
 [<a href="#Seeger:ivm02">Abstract</a>]
 [<a href="aistats03-final.ps.gz">gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
We present a method for the sparse greedy approximation of Bayesian Gaussian 
process regression, featuring a novel heuristic for very fast forward selection. 
Our method is essentially as fast as an equivalent one which selects the 
<span lang="en-gb">&quot;</span>support<span lang="en-gb">&quot;</span> patterns at random, yet it can outperform random selection on hard 
curve fitting tasks. More importantly, it leads to a sufficiently stable 
approximation of the log marginal likelihood of the training data, which can be optimised to adjust a large number of hyperparameters automatically. We 
demonstrate the model selection capabilities of the algorithm in a range of 
experiments. In line with the development of our method, we present a simple 
view on sparse approximations for GP models and their underlying assumptions and 
show relations to other methods.<br>
&nbsp;</P>


<!-- citation: (Lawrence:ivm02) -->
<A NAME=Lawrence:ivm02>
<P CLASS=CITATION-ABS>Lawrence, N. D.<span lang="en-gb">, M. Seeger</span> and R. Herbrich (200<span lang="en-gb">3</span>).
<SPAN CLASS=BIB-TITLE>Fast Sparse Gaussian Process Methods: The Informative 
Vector Machine</SPAN>. <span lang="en-gb">Presented at</span> 
<a href="http://www.nips.cc"><i>NIPS</i> 2002</a>.
 [<a href="#Seeger:ivm02">Abstract</a>]
 [<a href="ivm.ps.gz">gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE><span lang="en-gb">Abstract</span><P CLASS=BIB-ABS-TEXT>
We present a framework for sparse Gaussian process (GP) methods which uses 
forward selection with criteria based on information-theoretical principles, 
previously suggested for active learning. In contrast to most previous work on 
sparse GPs, our goal is not only to learn sparse predictors (which can be 
evaluated in O(d) rather than O(n), d<span lang="en-gb">&lt;&lt;</span>n,  n the number 
of training points), but also to perform training under strong restrictions on 
time and memory requirements. The scaling of our method is at most O(nd<sup><span lang="en-gb">2</span></sup>), and 
in large real-world classification experiments we show that it can match 
prediction performance of the popular support vector machine (SVM), yet it 
requires only a fraction of the training time. In contrast to the SVM, our 
approximation produces estimates of predictive probabilities (<span lang="en-gb">'</span>error bars'), 
allows for Bayesian model selection and is less complex in implementation.<br>
&nbsp;

<!-- citation: (Lawrence:sync01) -->
<A NAME=Lawrence:sync01>
<P CLASS=CITATION-ABS>Lawrence, N. D., A. I. T. Rowstron, C. M. Bishop and M. J. Taylor (2001).
<SPAN CLASS=BIB-TITLE>Optimising Synchronisation Times for Mobile Devices</SPAN>.
<span lang="en-gb">In</span> <i>NIPS</i> 2001.</a>[<a HREF=
jitcache.ps.gz
>gzipped PostScript</a>][<a href="jitcache.pdf">PDF</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
With the increasing number of users of mobile computing devices (e.g. personal digital assistants) and the
advent of third generation mobile phones, wireless
communications are becoming increasingly
important. Many applications rely on the device
maintaining a <i>replica</i> of a data-structure
which is stored on a server, for example news
databases, calendars and e-mail. In this paper we
explore the question of the optimal strategy for
synchronising such replicas. We utilise probabilistic
models to represent how the data-structures evolve
and to model user behaviour. We then formulate
objective functions which can be minimised with
respect to the synchronisation timings. We
demonstrate, using two real world data-sets, that a
user can obtain more up-to-date information using our
approach.</P>



<!-- citation: (Rowstron:sync01) -->
<A NAME=Rowstron:sync01>
<HR><P CLASS=CITATION-ABS>Rowstron, A. I. T., N. D. Lawrence and C. M. Bishop (2001).
<SPAN CLASS=BIB-TITLE>Probabilistic modelling of replica divergence</SPAN>.
Presented at <i>HotOS</i> 2001.</a>[<a HREF=
sync.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
It is common in distributed systems to replicate
data. In many cases this data evolves in a consistent
fashion and this evolution can be modelled. A
probabilistic model of the evolution allows us
to estimate the divergence of the replicas and can be
used by the application to alter its behaviour, for
example to control synchronisation times, to
determine the propagation of writes, and to convey to
the user information about how much the data may have
evolved.</P>
<P CLASS=BIB-ABS-TEXT>
In this paper, we describe how the evolution of the
data may be modelled and outline how the
probabilistic model may be utilised in various
applications, concentrating on a news database
example.
</P>

<!-- citation: (Lawrence:nrd01) -->
<A NAME=Lawrence:nrd01>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. (2001).
<SPAN CLASS=BIB-TITLE>Node relevance determination</SPAN>. Presented at <i>WIRN</i> 2001.
 [</a><a HREF=
structure.ps.gz
>gzipped PostScript</a>][<a href="structure.pdf">PDF</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Hierarchical Bayesian inference in parameterised models offers an
approach for controlling complexity. In this paper we utilise a novel
prior for the leaning of a model's structure. We call the prior node
relevance determination. It is applicable in a range of models
including sigmoid belief networks and Boltzmann machines. We
demonstrate how the approach may be applied to determine structure in
a multi-layer perceptron.</P>

<!-- citation: (Lawrence:noisy01) -->
<A NAME=Lawrence:noisy01>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. and B.&nbsp;Sch&ouml;lkopf (2001).
<SPAN CLASS=BIB-TITLE>Estimating a kernel fisher discriminant in the presence
  of label noise</SPAN>. Accepted for <i>ICML</i> 2001.
 [</a><a HREF=
noisyfisher.ps.gz
>gzipped PostScript</a>][<a href="noisyfisher.pdf">PDF</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Data noise is present in many machine learning problems domains, some of these
  are well studied but others have received less attention. In this paper we
  propose an algorithm for constructing a kernel Fisher discriminant (KFD) from
  training examples with <i>noisy labels</i>. The approach allows to associate
  with each example a probability of the label being flipped. We utilise an
  expectation maximization (EM) algorithm for updating the probabilities. The
  E-step uses class conditional probabilities estimated as a by-product of the
  KFD algorithm. The M-step updates the flip probabilities and determines the
  parameters of the discriminant. We have applied the approach to two
  real-world data-sets. The results show the feasibility of the approach.</P>

<!-- citation: (Lawrence:ltu01) -->
<A NAME=Lawrence:ltu01>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. (2001).
<SPAN CLASS=BIB-TITLE>Variational learning for multi-layer networks of linear
  threshold units</SPAN>.
In T.&nbsp;Jaakkola and T.&nbsp;Richardson (Eds.), <span CLASS=BIB-EMPH>Artificial
  Intelligence and Statistics</span>, Volume&nbsp;8, San Francisco, CA, pp.&nbsp;
  245&#150;252. Morgan Kauffman.
 [</a><a HREF=
ltus.ps.gz
>gzipped PostScript</a>][<a href="ltus.pdf">PDF</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Linear threshold units were originally proposed as models of biological
  neurons. They were widely studied in the context of the perceptron
  (Rosenblatt, 1962). Due to the difficulties of finding a general
  algorithm for networks with hidden nodes, they never passed into general use.
  We derive an algorithm in the context of graphical models and show how it may
  be applied in multi-layer networks of linear threshold units. We demonstrate
  the algorithm through three well known datasets.</P>

<!-- citation: (Lawrence:mixtures98) -->
<A NAME=Lawrence:mixtures98>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D., C.&nbsp;M. Bishop, and M.&nbsp;I. Jordan (1998).
<SPAN CLASS=BIB-TITLE>Mixture representations for inference and learning in
  Boltzmann machines</SPAN>.
In G.&nbsp;F. Cooper and S.&nbsp;Moral (Eds.), <span CLASS=BIB-EMPH>Uncertainty in
  Artificial Intelligence</span>, Volume&nbsp;14, San Fransisco, CA, pp.&nbsp;
  320&#150;327. Morgan Kauffman.
 [</a><a HREF=
boltzmann.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Boltzmann machines are undirected graphical models with two-state stochastic
  variables, in which the logarithms of the clique potentials are quadratic
  functions of the node states. They have been widely studied in the neural
  computing literature, although their practical applicability has been limited
  by the difficulty of finding an effective learning algorithm. One
  well-established approach, known as mean field theory, represents the
  stochastic distribution using a factorized approximation. However, the
  corresponding learning algorithm often fails to find a good solution. We
  conjecture that this is due to the implicit uni-modality of the mean field
  approximation which is therefore unable to capture multi-modality in the true
  distribution. In this paper we use variational methods to approximate the
  stochastic distribution using multi-modal <i>mixtures</i> of factorized
  distributions. We present results for both inference and learning to
  demonstrate the effectiveness of this approach.</P>

<!-- citation: (Bishop:mixtures97) -->
<A NAME=Bishop:mixtures97>
<HR><P CLASS=CITATION-ABS>
Bishop, C.&nbsp;M., N.&nbsp;D. Lawrence, T.&nbsp;S. Jaakkola, and M.&nbsp;I. Jordan (1998).
<SPAN CLASS=BIB-TITLE>Approximating posterior distributions in belief networks
  using mixtures</SPAN>.
In M.&nbsp;I. Jordan, M.&nbsp;J. Kearns, and S.&nbsp;A. Solla (Eds.), <span
  CLASS=BIB-EMPH>Advances in Neural Information Processing Systems</span>,
  Volume&nbsp;10, Cambridge, MA, pp.&nbsp; 416&#150;422. MIT Press.
 [</a><a HREF=
mixtures.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Exact inference in densely connected Bayesian networks is computationally
  intractable, and so there is considerable interest in developing effective
  approximation schemes. One approach which has been adopted is to bound the
  log likelihood using a mean-field approximating distribution. While this
  leads to a tractable algorithm, the mean field distribution is assumed to be
  factorial and hence unimodal. In this paper we demonstrate the feasibility of
  using a richer class of approximating distributions based on <i>mixtures</i>
  of mean field distributions. We derive an efficient algorithm for updating
  the mixture parameters and apply it to the problem of learning in sigmoid
  belief networks. Our results demonstrate a systematic improvement over simple
  mean field theory as the number of mixture components is increased.</P>

<hr>
<h2><a name="Seeger:ivm02">Submitted Conference Papers</a></h2>

<hr><H2>PhD Thesis</H2>
<!-- citation: (Lawrence:thesis00) -->
<A NAME=Lawrence:thesis00>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. (2000).
<span CLASS=BIB-EMPH>Variational Inference in Probabilistic Models</span>.
Ph.&nbsp;D. thesis, Computer Laboratory, University of Cambridge, New Museums
  Site, Pembroke Street, Cambridge, CB2 3QG, U.K.
Submitted 27th January 2000. 
[</a><a HREF=
thesis.ps.gz
>gzipped PostScript</a>][<a href="thesis.pdf">PDF</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
One of the key objectives of modern artificial intelligence is the
handling of uncertainty. Probability theory provides a framework for
handling of uncertainty in a principled manner. Probabilistic
inference is the process of reasoning under uncertainty and as such is
vital for both learning and decision making in probabilistic models.
For many models of interest this inference proves to be intractable
and to make progress approximate methods need to be considered. This
thesis concerns itself with a particular approximating formalism known
as variational inference (Jordan et al. 1998). Variational
inference has the advantage that it often provides bounds on
quantities of interest, such as marginalised likelihoods. In this
thesis we describe a general framework for the implementation of the
variational approach. We then explore the approach in several
different probabilistic models including undirected and directed
graphs, Bayesian neural networks and independent component
analysis. In those models which have been handled using variational
inference previously we show how we may improve the quality of our
inference engine by considering more complex variational
distributions.</P>

<hr><H2>Technical Reports</H2>

<!-- citation: (Lawrence:ltu_report00) -->
<A NAME=Lawrence:ltu_report00>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. (2000).
<SPAN CLASS=BIB-TITLE>Variational learning for multi-layer networks of linear
  threshold units</SPAN>.
Draft report, slightly extended version of <i>AISTATS</i> 2001 paper.
 [</a><a HREF=
ltupaper.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Linear threshold units were originally proposed as models of biological
  neurons. They were widely studied in the context of the perceptron
  (Rosenblatt, 1962). Due to the difficulties of finding a general
  algorithm for networks with hidden nodes, they never passed into general use.
  We derive an algorithm in the context of graphical models and show how it may
  be applied in multi-layer networks of linear threshold units. We demonstrate
  the algorithm through three well known datasets.</P>

<!-- citation: (Lawrence:ICA99) -->
<A NAME=Lawrence:ICA99>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. and C.&nbsp;M. Bishop (2000).
<SPAN CLASS=BIB-TITLE>Variational Bayesian independent component
  analysis</SPAN>.
Technical report. 
 [</a><a HREF=
bica_report.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Blind separation of signals through the info-max algorithm may be viewed as
  maximum likelihood learning in a latent variable model. In this paper we
  present an alternative approach to maximum likelihood learning in these
  models, namely Bayesian inference. It has already been shown how Bayesian
  inference can be applied to determine latent dimensionality in principal
  component analysis models (Bishop, 1998). In this paper we derive a
  similar approach for removing uneccessary source dimensions in an independent
  component analysis model. We present results on a toy data-set and on some
  artificially mixed images.</P>

<!-- citation: (lawrence:nnmixtures99) -->
<A NAME=lawrence:nnmixtures99>
<HR><P CLASS=CITATION-ABS>
Lawrence, N.&nbsp;D. and M.&nbsp;Azzouzi (1999).
<SPAN CLASS=BIB-TITLE>A variational Bayesian committee of neural
  networks</SPAN>.
Submitted to <i>Neural Networks</i>.
 [</a><a HREF=
nnmixture.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Exact inference in Bayesian neural networks is non analytic to compute and as a
  result approximate approaches such as the evidence procedure, Monte-Carlo
  sampling and variational inference have been proposed. In this paper we
  present a general overview of the Bayesian approach with a particular
  emphasis on the variational procedure. We then present a new approximating
  distribution based on <i>mixtures</i> of Gaussian distributions and show how
  it may be implemented. We present results on a simple toy problem and on two
  real world data-sets.</P>

<!-- citation: (Frey:markovian98) -->
<A NAME=Frey:markovian98>
<HR><P CLASS=CITATION-ABS>
Frey, B.&nbsp;J., N.&nbsp;D. Lawrence, and C.&nbsp;M. Bishop (1998).
<SPAN CLASS=BIB-TITLE>Markovian inference in belief networks</SPAN>.
Technical report, The Beckman Institute, University of Illinois at
  Urbana-Champaign, 405 North Mathews Avenue, Urbana, IL 61801, USA.
Originally submitted to <i>NIPS</i> 1998.
 [</a><a HREF=
mi.ps.gz
>gzipped PostScript</a>]
<P CLASS=BIB-ABS-TITLE>Abstract</P><P CLASS=BIB-ABS-TEXT>
Bayesian belief networks can represent the complicated probabilistic processes
  that form natural sensory inputs. Once the parameters of the network have
  been learned, nonlinear inferences about the input can be made by computing
  the posterior distribution over the hidden units (e.g., depth in stereo
  vision) given the input. Computing the posterior distribution exactly is not
  practical in richly-connected networks, but it turns out that by using a
  variational (a.k.a. mean field) method, it is easy to find a product-form
  distribution that approximates the true posterior distribution. This
  approximation assumes that the hidden variables are independent given the
  current input. In this paper, we explore a more powerful variational
  technique that models the posterior distribution using a Markov chain. We
  compare this method with inference using mean fields and mixtures of mean
  fields in randomly generated networks.</P>

<HR><!-- End of BibTeX-generated HTML -->
<p align="center"><font size="2">This page was last updated at 
<!--webbot
bot="Timestamp" S-Type="EDITED" S-Format="%H:%M:%S" startspan -->10:08:58<!--webbot
bot="Timestamp" endspan i-checksum="14073" -->
 on <!--webbot bot="Timestamp" S-Type="EDITED" S-Format="%d %B %Y" startspan -->27 August 2003<!--webbot bot="Timestamp" endspan i-checksum="31348" -->
 by Neil Lawrence (<a href="mailto:neil@thelawrences.net">neil@thelawrences.net</a>)</font></p>
<p align="center"><font size="2">
<!--webbot bot="Navigation" S-Type="siblings"
S-Orientation="horizontal" S-Rendering="text" B-Include-Home="FALSE"
B-Include-Up="TRUE" U-Page S-Target startspan --><!--webbot bot="Navigation" endspan i-checksum="0" -->
</font></p>

<!--msnavigation--></td></tr><!--msnavigation--></table></BODY>
</HTML>